{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3160afdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7fc0cae98ac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4654b25d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T19:57:53.734187371Z",
     "start_time": "2024-02-20T19:57:51.671448212Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03aa166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T19:59:25.208029148Z",
     "start_time": "2024-02-20T19:57:57.472351999Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV files into pandas dataframes\n",
    "df1 = pd.read_csv('dataset/Code_cell.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d8db71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T20:00:04.172315053Z",
     "start_time": "2024-02-20T20:00:03.120883174Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Changing the dataframe\n",
    "df1 = df1[['cell_id', 'notebook_id', 'code_imports', 'defined_functions', 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65832c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T20:00:17.442357234Z",
     "start_time": "2024-02-20T20:00:07.052767931Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>notebook_id</th>\n",
       "      <th>code_imports</th>\n",
       "      <th>defined_functions</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>json pprint dateutil.parser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>import json\\nimport pprint\\n\\nimport dateutil....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission['created_at'] = dateutil.parser.par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pprint.pprint(submission)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>os</td>\n",
       "      <td>NaN</td>\n",
       "      <td>import os\\nPROJECT = \"cloud-training-demos\" # ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%%bash\\ngcloud config set project $PROJECT\\ngc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%%bash\\nrm -rf mnistmodel.tar.gz mnist_trained...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%%bash\\nOUTDIR=gs://${BUCKET}/mnist/trained_${...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>google.datalab.ml.TensorBoard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from google.datalab.ml import TensorBoard\\nTen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>for pid in TensorBoard.list()[\"pid\"]:\\n    Ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%%bash\\nMODEL_NAME=\"mnist\"\\nMODEL_VERSION=${MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>json codecs matplotlib.pyplot tensorflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>import json, codecs\\nimport matplotlib.pyplot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%%bash\\ngcloud ml-engine predict \\\\n    --mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trainingInput:\\n    scaleTier: CUSTOM\\n    mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%%bash\\nOUTDIR=gs://${BUCKET}/mnist/trained_${...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>subprocess.check_output</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from subprocess import check_output\\nprint(che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>numpy pandas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>embedding_matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>matplotlib.pyplot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>import matplotlib.pyplot as plt\\n%matplotlib i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cell_id  notebook_id                              code_imports  \\\n",
       "0         1            1               json pprint dateutil.parser   \n",
       "1         2            1                                       NaN   \n",
       "2         3            1                                       NaN   \n",
       "3         4            1                                       NaN   \n",
       "4         6            2                                        os   \n",
       "5         7            2                                       NaN   \n",
       "6         9            2                                       NaN   \n",
       "7        11            2                                       NaN   \n",
       "8        13            2             google.datalab.ml.TensorBoard   \n",
       "9        14            2                                       NaN   \n",
       "10       18            2                                       NaN   \n",
       "11       20            2  json codecs matplotlib.pyplot tensorflow   \n",
       "12       22            2                                       NaN   \n",
       "13       24            2                                       NaN   \n",
       "14       26            2                                       NaN   \n",
       "15       29            3                   subprocess.check_output   \n",
       "16       30            3                              numpy pandas   \n",
       "17       68            3                                       NaN   \n",
       "18       85            4                         matplotlib.pyplot   \n",
       "19      126            4                                       NaN   \n",
       "\n",
       "   defined_functions                                             source  \n",
       "0                NaN  import json\\nimport pprint\\n\\nimport dateutil....  \n",
       "1                NaN  submission['created_at'] = dateutil.parser.par...  \n",
       "2                NaN                          pprint.pprint(submission)  \n",
       "3                NaN                                                NaN  \n",
       "4                NaN  import os\\nPROJECT = \"cloud-training-demos\" # ...  \n",
       "5                NaN  %%bash\\ngcloud config set project $PROJECT\\ngc...  \n",
       "6                NaN  %%bash\\nrm -rf mnistmodel.tar.gz mnist_trained...  \n",
       "7                NaN  %%bash\\nOUTDIR=gs://${BUCKET}/mnist/trained_${...  \n",
       "8                NaN  from google.datalab.ml import TensorBoard\\nTen...  \n",
       "9                NaN  for pid in TensorBoard.list()[\"pid\"]:\\n    Ten...  \n",
       "10               NaN  %%bash\\nMODEL_NAME=\"mnist\"\\nMODEL_VERSION=${MO...  \n",
       "11               NaN  import json, codecs\\nimport matplotlib.pyplot ...  \n",
       "12               NaN  %%bash\\ngcloud ml-engine predict \\\\n    --mode...  \n",
       "13               NaN  trainingInput:\\n    scaleTier: CUSTOM\\n    mas...  \n",
       "14               NaN  %%bash\\nOUTDIR=gs://${BUCKET}/mnist/trained_${...  \n",
       "15               NaN  from subprocess import check_output\\nprint(che...  \n",
       "16               NaN            import numpy as np\\nimport pandas as pd  \n",
       "17               NaN                                   embedding_matrix  \n",
       "18               NaN  import matplotlib.pyplot as plt\\n%matplotlib i...  \n",
       "19               NaN                                                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.to_pickle('df1.pkl')\n",
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d2b9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T20:00:56.641546577Z",
     "start_time": "2024-02-20T20:00:20.313672184Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('dataset/Md_cell.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695bb86c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T20:01:21.776092847Z",
     "start_time": "2024-02-20T20:01:21.481340308Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Changing the dataframe\n",
    "df2 = df2[['cell_id', 'notebook_id', 'source']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f791dd9",
   "metadata": {},
   "source": [
    "Pandas dataframe head 20 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7b9808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T20:01:30.351482362Z",
     "start_time": "2024-02-20T20:01:25.044171109Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>notebook_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td># MNIST Image Classification with TensorFlow o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>## Run as a Python module\\n\\nIn the previous n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>**Now, let's do it on Cloud ML Engine so we ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>## Monitoring training with TensorBoard\\n\\nUse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Here's what it looks like with a linear model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Here are my results:\\n\\nModel | Accuracy | Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>## Deploying and predicting with model\\n\\nDepl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>To predict with the model, let's take one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>Send it to the prediction service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>## DO NOT RUN anything beyond this point\\n\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>This takes &lt;b&gt;13 hours and 250 ML Units&lt;/b&gt;, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;pre&gt;\\n# Copyright 2017 Google Inc. All Rights...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td># Keras - Bidirectional LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>### Import keras Libs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>### Read Glove Word Vectors : word -&gt; vector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>## Submission File Generate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td># Logistic Regression (Classification)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>So far we have been looking at regression prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>Lets say we want to classify the vehicles by '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>## Why Linear Function does not work\\nNow we c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cell_id  notebook_id                                             source\n",
       "0         5            2  # MNIST Image Classification with TensorFlow o...\n",
       "1         8            2  ## Run as a Python module\\n\\nIn the previous n...\n",
       "2        10            2  **Now, let's do it on Cloud ML Engine so we ca...\n",
       "3        12            2  ## Monitoring training with TensorBoard\\n\\nUse...\n",
       "4        15            2  Here's what it looks like with a linear model ...\n",
       "5        16            2  Here are my results:\\n\\nModel | Accuracy | Tim...\n",
       "6        17            2  ## Deploying and predicting with model\\n\\nDepl...\n",
       "7        19            2  To predict with the model, let's take one of t...\n",
       "8        21            2                  Send it to the prediction service\n",
       "9        23            2  ## DO NOT RUN anything beyond this point\\n\\nTh...\n",
       "10       25            2  This takes <b>13 hours and 250 ML Units</b>, s...\n",
       "11       27            2  <pre>\\n# Copyright 2017 Google Inc. All Rights...\n",
       "12       28            3                      # Keras - Bidirectional LSTM \n",
       "13       31            3                              ### Import keras Libs\n",
       "14       56            3       ### Read Glove Word Vectors : word -> vector\n",
       "15       76            3                        ## Submission File Generate\n",
       "16       82            4             # Logistic Regression (Classification)\n",
       "17       83            4  So far we have been looking at regression prob...\n",
       "18       88            4  Lets say we want to classify the vehicles by '...\n",
       "19       92            4  ## Why Linear Function does not work\\nNow we c..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.to_pickle('df2.pkl')\n",
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d329fc71",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-20T20:01:52.468493098Z"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load dataframes from pickle files\n",
    "df1 = pd.read_pickle('df1.pkl')\n",
    "#df_code = df1.head(1000000)\n",
    "df2 = pd.read_pickle('df2.pkl')\n",
    "#df_md = df2.head(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa958c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes based on the common column\n",
    "merged_df = dd.merge(df1, df2, on='notebook_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows based on the condition\n",
    "merged_df = merged_df.loc[merged_df['cell_id_x'] > merged_df['cell_id_y']]\n",
    "\n",
    "# Keep the last Markdown cell before the Code cell while removing duplicates\n",
    "merged_df.drop_duplicates(subset=['cell_id_x'], keep='last')\n",
    "\n",
    "# If you want to reset the index after removing rows\n",
    "merged_df.reset_index(drop=True)\n",
    "\n",
    "merged_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f550867c",
   "metadata": {
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask_expr/_core.py:467\u001b[0m, in \u001b[0;36mExpr.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Merge' object has no attribute 'to_pickle'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask_expr/_collection.py:619\u001b[0m, in \u001b[0;36mFrameBase.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Fall back to `expr` API\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;66;03m# (Making sure to convert to/from Expr)\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(val):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask_expr/_core.py:488\u001b[0m, in \u001b[0;36mExpr.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    487\u001b[0m link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/dask-contrib/dask-expr/blob/main/README.md#api-coverage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis often means that you are attempting to use an unsupported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI function. Current API coverage is documented here: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Merge' object has no attribute 'to_pickle'\n\nThis often means that you are attempting to use an unsupported API function. Current API coverage is documented here: https://github.com/dask-contrib/dask-expr/blob/main/README.md#api-coverage.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the merged dataframe to a new pickle file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pickle\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_train.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask_expr/_collection.py:3044\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   3042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   3043\u001b[0m     \u001b[38;5;66;03m# Fall back to `BaseFrame.__getattr__`\u001b[39;00m\n\u001b[0;32m-> 3044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask_expr/_collection.py:625\u001b[0m, in \u001b[0;36mFrameBase.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;66;03m# Raise original error\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask_expr/_collection.py:614\u001b[0m, in \u001b[0;36mFrameBase.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;66;03m# Prioritize `FrameBase` attributes\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m             \u001b[38;5;66;03m# Fall back to `expr` API\u001b[39;00m\n\u001b[1;32m    618\u001b[0m             \u001b[38;5;66;03m# (Making sure to convert to/from Expr)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_pickle'"
     ]
    }
   ],
   "source": [
    "# Save the merged dataframe to a new pickle file\n",
    "merged_df.to_pickle('df_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f391ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset as csv file\n",
    "merged_df.to_csv('merged_file.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
